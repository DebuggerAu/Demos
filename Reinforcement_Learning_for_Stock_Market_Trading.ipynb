{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reinforcement Learning for Stock Market Trading.ipynb",
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DebuggerAu/Demos/blob/master/Reinforcement_Learning_for_Stock_Market_Trading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFYKMfEEEzni"
      },
      "source": [
        "## Stage 1: Installing dependencies and environment setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEPWe6QNErug",
        "outputId": "6e570549-b441-4c44-fa06-b3f97471cc8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        }
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0rc0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/12/8c64cc62149cc21c70c55018502831bbf4d42bd62bed196df7de6830d21b/tensorflow_gpu-2.0.0rc0-cp36-cp36m-manylinux2010_x86_64.whl (380.5MB)\n",
            "\u001b[K     |████████████████████████████████| 380.5MB 85kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (0.1.7)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (1.11.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (1.15.0)\n",
            "Collecting tb-nightly<1.15.0a20190807,>=1.15.0a20190806 (from tensorflow-gpu==2.0.0rc0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/88/24b5fb7280e74c7cf65bde47c171547fd02afb3840cff41bcbe9270650f5/tb_nightly-1.15.0a20190806-py3-none-any.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 37.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (0.8.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (1.16.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (0.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (3.0.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (3.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (1.0.8)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601 (from tensorflow-gpu==2.0.0rc0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/28/f2a27a62943d5f041e4a6fd404b2d21cb7c59b2242a4e73b03d9ba166552/tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl (501kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 38.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (0.33.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0rc0) (0.15.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0rc0) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0rc0) (41.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0rc0) (2.8.0)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.15.0a20190806 tensorflow-gpu-2.0.0rc0 tf-estimator-nightly-1.14.0.dev2019080601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lafKy3gGRFW",
        "outputId": "f06f28ff-83be-411d-ad44-7db4c9b3d0e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pandas-datareader\n",
        "!pip install yfinance"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from pandas-datareader) (5.3.0)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.10/dist-packages (from pandas-datareader) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pandas-datareader) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23->pandas-datareader) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23->pandas-datareader) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23->pandas-datareader) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23->pandas-datareader) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.23->pandas-datareader) (1.17.0)\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.2.51-py2.py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.32.3)\n",
            "Collecting multitasking>=0.0.7 (from yfinance)\n",
            "  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (5.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2024.2)\n",
            "Collecting frozendict>=2.3.4 (from yfinance)\n",
            "  Downloading frozendict-2.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
            "Collecting peewee>=3.16.2 (from yfinance)\n",
            "  Downloading peewee-3.17.8.tar.gz (948 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.2/948.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n",
            "Collecting html5lib>=1.1 (from yfinance)\n",
            "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.12.14)\n",
            "Downloading yfinance-0.2.51-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.7/104.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading frozendict-2.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
            "Building wheels for collected packages: peewee\n",
            "  Building wheel for peewee (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peewee: filename=peewee-3.17.8-cp310-cp310-linux_x86_64.whl size=843071 sha256=6aad5fc84090b81228ef667826da79836a4fe3d10e0a7681b1e04172f1faa333\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/79/e5/8838db0594cc6c587142fd2563356392ade6255c5930411069\n",
            "Successfully built peewee\n",
            "Installing collected packages: peewee, multitasking, html5lib, frozendict, yfinance\n",
            "Successfully installed frozendict-2.4.6 html5lib-1.1 multitasking-0.0.11 peewee-3.17.8 yfinance-0.2.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0BVbvetGrlR"
      },
      "source": [
        "## Stage 2: Importing project dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qALiMginGiMW"
      },
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas_datareader as data_reader\n",
        "import yfinance as yf\n",
        "from tqdm import tqdm_notebook, tqdm\n",
        "from collections import deque"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drGd9adHGuje",
        "outputId": "351cc723-8297-4c33-e9ba-e6a97f701785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.15.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__E4SMMaGwqb"
      },
      "source": [
        "## Stage 3: Building the AI Trader network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCggfrCtGyiG"
      },
      "source": [
        "class AI_Trader():\n",
        "\n",
        "  def __init__(self, state_size, action_space=3, model_name=\"AITrader\"): #Stay, Buy, Sell\n",
        "\n",
        "    self.state_size = state_size\n",
        "    self.action_space = action_space\n",
        "    self.memory = deque(maxlen=2000)\n",
        "    self.inventory = []\n",
        "    self.model_name = model_name\n",
        "\n",
        "    # Define hyperparamaters\n",
        "    self.gamma = 0.95\n",
        "    self.epsilon = 1.0\n",
        "    self.epsilon_final = 0.01\n",
        "    self.epsilon_decay = 0.995\n",
        "\n",
        "    # Call a function  to build a model trought this class constructor\n",
        "    # More parameters could be ustilized to programaticaly define network size (layers and neurons)\n",
        "    self.model = self.model_builder()\n",
        "\n",
        "\n",
        "  def model_builder(self):\n",
        "\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(units=32, activation='relu', input_dim=self.state_size))\n",
        "    model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(units=self.action_space, activation='linear'))\n",
        "    model.compile(loss='mse', optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Trade function that takes state as an input and returns an action\n",
        "  # to perform in perticular state\n",
        "  def trade(self, state):\n",
        "\n",
        "    # Should we perform a renadom generated action or action defined in model?\n",
        "\n",
        "    # If value from our random generator is smaller or equal to our epsilon\n",
        "    #     then we will retun a random action from action_space [0-3)\n",
        "    if random.random() <= self.epsilon:\n",
        "      return random.randrange(self.action_space)\n",
        "\n",
        "    # If our random is greater than epsilon then we will use model to perform action\n",
        "    actions = self.model.predict(state)\n",
        "    # return only a one number defining an action (#Stay - 0 , Buy - 1, Sell - 2)\n",
        "    #    that has maximum probability\n",
        "    return np.argmax(actions[0])\n",
        "\n",
        "\n",
        "\n",
        "  def batch_train(self, batch_size):\n",
        "\n",
        "    batch = []\n",
        "\n",
        "    # Iterrate in momory, we do not want to randolmy select data as we are dealing with\n",
        "    #    time constraint data. We will always sample from the end of memory size of bath\n",
        "    for i in range(len(self.memory) - batch_size + 1, len(self.memory)):\n",
        "      # insert data from memory to batch\n",
        "      batch.append(self.memory[i])\n",
        "\n",
        "\n",
        "    # Iterate trought batch of data and train the model for each sample from batch\n",
        "    # Order of variables in for loop is important\n",
        "    for state, action, reward, next_state, done in batch:\n",
        "      # Reward if agent is in terminal state\n",
        "      reward = reward\n",
        "      # Check that agent is not in terminal state\n",
        "      # If not in terminal state calculate reward for actions that could be played\n",
        "      if not done:\n",
        "        # Discounted total reward:\n",
        "        reward = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
        "      # Target variable that is predicted by the model (action)\n",
        "      target = self.model.predict(state)\n",
        "      target[0][action] = reward\n",
        "\n",
        "      self.model.fit(state, target, epochs=1, verbose=0)\n",
        "\n",
        "    # We will decrease epsilon parameter that is 1 as defined in __init__  so\n",
        "    #    so we can stop performing random actions at some point\n",
        "    if self.epsilon > self.epsilon_final:\n",
        "      self.epsilon *= self.epsilon_decay"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tcUyJMnS479"
      },
      "source": [
        "## Stage 4: Dataset preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya_4XPUMS8Pe"
      },
      "source": [
        "### Defining helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK6UDGe0TACz"
      },
      "source": [
        "#### Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzXG-49iSZX3"
      },
      "source": [
        "# Usually used at the end of a network for binary classifictation\n",
        "# It changes range of input to scale of [0,1]\n",
        "# So we can normalize input data for comparision day by day if they are on different scale\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + math.exp(-x))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VRbmx_OTDtZ"
      },
      "source": [
        "#### Price format function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8vVBL8YTGaE"
      },
      "source": [
        "def stocks_price_format(n):\n",
        "  if n < 0:\n",
        "    return \"- $ {0:2f}\".format(abs(n))\n",
        "  else:\n",
        "    return \"$ {0:2f}\".format(abs(n))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8_bXTiFTHnH"
      },
      "source": [
        "#### Dataset loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pXYjiBwNRsV",
        "outputId": "c4a03b93-a8a7-49ac-d343-fc932cc49ea7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check the data gathered with pandas data_reader:\n",
        "dataset = yf.download('SPY', start = '2012-01-01', end='2025-01-01')\n",
        "\n",
        "#data_reader.DataReader(name=\"AAPL\", data_source=\"google\")\n",
        "print(\"Data set top rows:\", \"\\n\" ,dataset.head())\n",
        "\n",
        "print(\"Test some cutting with pandas\")\n",
        "print(\"Start date: \", str(dataset.index[0]).split()[0])\n",
        "print(\"End date: \", str(dataset.index[-1]).split()[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data set top rows: \n",
            " Price            Close        High         Low        Open     Volume\n",
            "Ticker             SPY         SPY         SPY         SPY        SPY\n",
            "Date                                                                 \n",
            "2012-01-03  100.752831  101.448226  100.697515  100.958289  193697900\n",
            "2012-01-04  100.910919  100.997844  100.128604  100.515810  127186500\n",
            "2012-01-05  101.179565  101.329709   99.907319  100.365647  173895000\n",
            "2012-01-06  100.918777  101.321790  100.586887  101.305983  148050000\n",
            "2012-01-09  101.163780  101.290206  100.681746  101.147972   99530200\n",
            "Test some cutting with pandas\n",
            "Start date:  2012-01-03\n",
            "End date:  2024-12-31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAcu8ZZzTNwm"
      },
      "source": [
        "def dataset_loader(stock_name, web_data_source=\"yahoo\"):\n",
        "\n",
        "  #Use pandas data reader for reading stock data from warious sources like \"yahoo\", \"google\"\n",
        "  dataset = data_reader.DataReader(name=stock_name, data_source=\"yahoo\")\n",
        "\n",
        "  # Get start and end time to variables from dataset\n",
        "  start_date = str(dataset.index[0]).split()[0]\n",
        "  end_date = str(dataset.index[-1]).split()[0]\n",
        "\n",
        "  # Model will use \"Close\" column for training\n",
        "  close = dataset['Close']\n",
        "\n",
        "  return close"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eG5ueRzH1Kh8"
      },
      "source": [
        "### State creator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwTS0EyZ0O1k"
      },
      "source": [
        "# Data -> dataset to predict from, gathered by data:loader()\n",
        "# Timestep -> Day in the dataset that we want to predict for [0:datalength]\n",
        "# window_suze -> how many days in past we want to use to predict current status[1:datalength]\n",
        "#         Try different setup to see what creates best fit\n",
        "def state_creator(data, timestep, window_size):\n",
        "\n",
        "  # starting day of our state\n",
        "  starting_id = timestep - window_size + 1\n",
        "\n",
        "  if starting_id >= 0:\n",
        "    windowed_data = data[starting_id:timestep+1]\n",
        "  else:\n",
        "    # Replicate member (data[0]) needed times\n",
        "    windowed_data = - starting_id * [data[0]] + list(data[0:timestep+1])\n",
        "\n",
        "  state = []\n",
        "  # Iterate trough whole windowed_data minus current state (-1)\n",
        "  for i in range(window_size - 1):\n",
        "    # Normalize the difference from current day and the next day\n",
        "    # Because the prices can be very different and we want them on same scale\n",
        "    state.append(sigmoid(windowed_data[i+1] - windowed_data[i]))\n",
        "\n",
        "  return np.array([state])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV2a68QC34N-"
      },
      "source": [
        "### Loading a dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acuYlqD83xcX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc32541a-3665-40c5-ee38-fc3e13636555"
      },
      "source": [
        "# stage data for Apple\n",
        "stock_name = \"AAPL\"\n",
        "data = dataset = yf.download(stock_name , start = '2012-01-01', end='2025-01-01')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_KUeBY14o8Z"
      },
      "source": [
        "## Stage 5: Training the AI Trader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkyW12-L4qo_"
      },
      "source": [
        "### Setting hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKfuoXO84c5X"
      },
      "source": [
        "window_size = 10\n",
        "episodes = 1000 # same as epoch\n",
        "epochs = 50\n",
        "learning_rate = 0.01\n",
        "decay_rate = learning_rate / epochs\n",
        "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate, decay=decay_rate)\n",
        "\n",
        "batch_size = 32\n",
        "data_samples = len(data) - 1 # discard last value, that we will predict on"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2kvNZx24sJ7"
      },
      "source": [
        "### Defining the Trader model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4LmF2V94trY"
      },
      "source": [
        "trader = AI_Trader(window_size)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y66jkzwW4wNV",
        "outputId": "4b7a2325-c3ad-437e-f60a-78f58e774deb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "trader.model.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 32)                352       \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11171 (43.64 KB)\n",
            "Trainable params: 11171 (43.64 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRip_rac5zHS"
      },
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0tytPl-5hdg",
        "outputId": "247ff29d-b4ec-4a32-f989-c8e64a005ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "for episode in range(1, episodes + 1):\n",
        "\n",
        "  # To keep track of training process\n",
        "  # .format populates {} with variables in .format(x,y)\n",
        "  print(\"Episode: {}/{}\".format(episode, episodes))\n",
        "\n",
        "  # Create state\n",
        "  # second parameter is timestep = 0\n",
        "  state = state_creator(data, 0, window_size + 1)\n",
        "\n",
        "  total_profit = 0\n",
        "  # Empty inventory before starting episode\n",
        "  trader.inventory = []\n",
        "\n",
        "  # One timestep is one day so number of timesteps we have represent data we have\n",
        "  # tqdm is used for visualization\n",
        "  for t in tqdm(range(data_samples)):\n",
        "\n",
        "    # First we will access action that is going to be taken by model\n",
        "    action = trader.trade(state)\n",
        "\n",
        "    # Use action to get to next state(t+)\n",
        "    next_state = state_creator(data, t+1, window_size + 1)\n",
        "    # As we did not calculate anything up to this point reward is 0\n",
        "    reward = 0\n",
        "\n",
        "    if action == 1: #Buying\n",
        "      # Put buyed stock to inventory to trade with\n",
        "      trader.inventory.append(data[t])\n",
        "      print(\"AI Trader bought: \", stocks_price_format(data[t]))\n",
        "\n",
        "    # To sell we need to have something in inventory\n",
        "    elif action == 2 and len(trader.inventory) > 0: #Selling\n",
        "      # Check buy price, pop removes first value from list\n",
        "      buy_price = trader.inventory.pop(0)\n",
        "\n",
        "      # If we gain money (current price - buy price) we have reward\n",
        "      #    if we lost money then reward is 0\n",
        "      reward = max(data[t] - buy_price, 0)\n",
        "      total_profit += data[t] - buy_price\n",
        "      print(\"AI Trader sold: \", stocks_price_format(data[t]), \" Profit: \" + stocks_price_format(data[t] - buy_price) )\n",
        "\n",
        "    # if t is last sample in our dateset we are done\n",
        "    #     we do not have any steps to perform in current episode\n",
        "    if t == data_samples - 1:\n",
        "      done = True\n",
        "    else:\n",
        "      done = False\n",
        "\n",
        "    # Append all data to trader-agent memory, experience buffer\n",
        "    trader.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    # change state to next state, so we are done with an episode\n",
        "    state = next_state\n",
        "\n",
        "    if done:\n",
        "      print(\"########################\")\n",
        "      print(\"TOTAL PROFIT: {}\".format(total_profit))\n",
        "      print(\"########################\")\n",
        "\n",
        "    # Chekc if we have more information in our memory than batch size\n",
        "    if len(trader.memory) > batch_size:\n",
        "      trader.batch_train(batch_size)\n",
        "\n",
        "  # Save the model every 10 episodes\n",
        "  if episode % 10 == 0:\n",
        "    trader.model.save(\"ai_trader_{}.h5\".format(episode))\n",
        ""
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 1/1000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-50dd6150410e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# Create state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m# second parameter is timestep = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mtotal_profit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-18e04a9c9341>\u001b[0m in \u001b[0;36mstate_creator\u001b[0;34m(data, timestep, window_size)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Replicate member (data[0]) needed times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mwindowed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstarting_id\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4099\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_single_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4101\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4102\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_multilevel\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4158\u001b[0m         \u001b[0;31m# self.columns is a MultiIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4159\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4161\u001b[0m             \u001b[0mnew_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3040\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_level_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_maybe_to_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_get_level_indexer\u001b[0;34m(self, key, level, indexer)\u001b[0m\n\u001b[1;32m   3389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3390\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3391\u001b[0;31m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc_single_level_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lexsort_depth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_get_loc_single_level_index\u001b[0;34m(self, level_index, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlevel_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    }
  ]
}